{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9fc126",
   "metadata": {},
   "source": [
    "# Process Climate Processing Centre (CPC) Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0ab53",
   "metadata": {},
   "source": [
    "### Prepare Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492159c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import data manipulation libraries\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Import geospatial libraries\n",
    "import geopandas as gpd\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/Users/jessicarapson/Documents/GitHub/water-supply-forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b6474",
   "metadata": {},
   "source": [
    "### Process Precipitation Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f61f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store data\n",
    "year_data = []\n",
    "\n",
    "# Set header\n",
    "header_line = ['YEAR','MN','LEAD','CD','R','98','95','90','80','70','60','50','40',\n",
    "               '30','20','10','5','2','F MEAN','C MEAN','F SD','C SD','POW']\n",
    "\n",
    "# Loop through years\n",
    "for i in range(1994,2024):\n",
    "    \n",
    "    # Set path to data\n",
    "    path = 'assets/data/cpc_outlooks/raw_data/cpcllfpd.' + str(i) + '.dat'\n",
    "    \n",
    "    # Open the .dat file in read mode\n",
    "    with open(path, 'r') as file:\n",
    "        # Skip the first line\n",
    "        file.readline()\n",
    "\n",
    "        # Read the rest of the file contents\n",
    "        data = file.readlines()[1:]\n",
    "\n",
    "    # Process the data to extract information \n",
    "    parsed_data = []\n",
    "    for line in data:\n",
    "        # Split each line on the spaces\n",
    "        row = line.strip().split(' ')\n",
    "        parsed_data.append([i for i in row if i != ''][:23])\n",
    "        \n",
    "    year_data.extend(parsed_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_prec = pd.DataFrame(year_data, columns=header_line)\n",
    "\n",
    "# Remove rows with no data\n",
    "df_prec['POW'] = pd.to_numeric(df_prec['POW'], errors='coerce')\n",
    "df_prec = df_prec[pd.notnull(df_prec['POW'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9887a5b",
   "metadata": {},
   "source": [
    "### Process Temperature Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163fa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store data\n",
    "year_data = []\n",
    "\n",
    "# Set header\n",
    "header_line = ['YEAR','MN','LEAD','CD','R','98','95','90','80','70','60','50','40',\n",
    "              '30','20','10','5','2','F MEAN','C MEAN','F SD','C S']\n",
    "\n",
    "# Loop through years\n",
    "for i in range(1994,2024):\n",
    "    \n",
    "    # Set path to data\n",
    "    path = 'assets/data/cpc_outlooks/raw_data/cpcllftd.' + str(i) + '.dat'\n",
    "    \n",
    "    # Open the .dat file in read mode\n",
    "    with open(path, 'r') as file:\n",
    "        # Skip the first line\n",
    "        file.readline()\n",
    "\n",
    "        # Read the rest of the file contents\n",
    "        data = file.readlines()[1:]\n",
    "\n",
    "    # Process the data to extract information \n",
    "    parsed_data = []\n",
    "    for line in data:\n",
    "        # Split each line on the spaces\n",
    "        row = line.strip().split(' ')\n",
    "        parsed_data.append([i for i in row if i != ''][:22])\n",
    "        \n",
    "    year_data.extend(parsed_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_temp = pd.DataFrame(year_data, columns=header_line)\n",
    "\n",
    "# Remove rows with no data\n",
    "df_temp['C S'] = pd.to_numeric(df_temp['C S'], errors='coerce')\n",
    "df_temp = df_temp[pd.notnull(df_temp['C S'])]\n",
    "df_temp['98'] = pd.to_numeric(df_temp['98'], errors='coerce')\n",
    "df_temp = df_temp[pd.notnull(df_temp['98'])]\n",
    "\n",
    "# Export to CSV\n",
    "df_temp.to_csv('assets/data/cpc_outlooks/cpc_temp.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de724c7",
   "metadata": {},
   "source": [
    "### Join Data to Forecast Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fb9c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spatial data\n",
    "gdf_cd = gpd.read_file('assets/data/cpc_climate_divisions.gpkg')\n",
    "gdf_sites = gpd.read_file('assets/data/geospatial.gpkg')\n",
    "\n",
    "# Perform a spatial join between the GeoDataFrames\n",
    "joined = gpd.sjoin(gdf_sites, gdf_cd, how='left', op='intersects')\n",
    "\n",
    "# Group by 'site_id' and 'CD' and calculate the area of the intersection\n",
    "grouped = joined.groupby(['site_id', 'CD']).size().reset_index(name='count')\n",
    "\n",
    "# Find the index of the maximum count for each 'site_id'\n",
    "max_count = grouped.groupby('site_id')['count'].idxmax()\n",
    "\n",
    "# Get the corresponding 'CD' with the largest overlapping area for each 'site_id'\n",
    "largest_CD_per_site = grouped.loc[max_count]\n",
    "\n",
    "# Merge the 'site_id' data with the corresponding 'CD' containing the largest overlap\n",
    "site_to_cd_dict = largest_CD_per_site.merge(gdf_cd, on='CD', how='left')[['site_id','CD']]\n",
    "\n",
    "# Right join data on site for precipitation\n",
    "df_prec['CD'] = df_prec['CD'].apply(int)\n",
    "df_prec = pd.merge(df_prec, site_to_cd_dict, on='CD', how='right')\n",
    "\n",
    "# Right join data on site for temperature\n",
    "df_temp['CD'] = df_temp['CD'].apply(int)\n",
    "dfdf_temp_prec = pd.merge(df_temp, site_to_cd_dict, on='CD', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be2b17",
   "metadata": {},
   "source": [
    "### Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b44e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export precipitation data\n",
    "df_prec.to_csv('assets/data/cpc_outlooks/cpc_prec.csv', index=False)  \n",
    "\n",
    "# Export temperature data\n",
    "df_temp.to_csv('assets/data/cpc_outlooks/cpc_temp.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afdc22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
