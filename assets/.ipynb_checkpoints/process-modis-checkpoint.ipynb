{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b795cf",
   "metadata": {},
   "source": [
    "# Process MODIS Vegetation Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48500b4a",
   "metadata": {},
   "source": [
    "### Prepare Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4cf4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicarapson/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import system libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, mapping\n",
    "\n",
    "# Import geospatial libraries\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import rasterio.mask\n",
    "\n",
    "# Import API libraries\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import odc.stac\n",
    "import rich.table\n",
    "\n",
    "# Import visualisation libraries (optional)\n",
    "import xrspatial\n",
    "from datashader.transfer_functions import shade, stack\n",
    "from datashader.colors import Elevation\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/Users/jessicarapson/Documents/GitHub/water-supply-forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ee157",
   "metadata": {},
   "source": [
    "### Load Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4c8bfe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MODIS for: 2000 hungry_horse_reservoir_inflow (1/26)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 68\u001b[0m\n\u001b[1;32m     62\u001b[0m datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m search \u001b[38;5;241m=\u001b[39m catalog\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     64\u001b[0m     collections\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodis-13A1-061\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     65\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[1;32m     66\u001b[0m     datetime\u001b[38;5;241m=\u001b[39mdatetime,\n\u001b[1;32m     67\u001b[0m )\n\u001b[0;32m---> 68\u001b[0m items_season[name] \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     69\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(search\u001b[38;5;241m.\u001b[39mitem_collection())\n\u001b[1;32m     70\u001b[0m items_trunc \u001b[38;5;241m=\u001b[39m items[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mtuple\u001b[39m(x\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m items]))]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pystac/item_collection.py:107\u001b[0m, in \u001b[0;36mItemCollection.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pystac\u001b[38;5;241m.\u001b[39mItem:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Call API\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Load in site geospatial data\n",
    "gdf_sites = gpd.read_file('assets/data/geospatial.gpkg')\n",
    "\n",
    "# Initialize an empty list to store catchment bounding boxes\n",
    "site_bboxes = []\n",
    "\n",
    "# Iterate through each polygon (catchment) in the GeoDataFrame\n",
    "for index, row in gdf_sites.iterrows():\n",
    "    # Get the bounding box for each polygon\n",
    "    bbox = row.geometry.bounds  # Extract the bounding box as (minx, miny, maxx, maxy)\n",
    "    site_bboxes.append(bbox)  # Append the bounding box to the list\n",
    "    \n",
    "# Initialise dataframes to store extracted information\n",
    "df_jan = pd.DataFrame(\n",
    "    {'site_id': gdf_sites['site_id'],'year': np.nan,'month': np.nan,\n",
    "     'max_veg':np.nan,'min_veg': np.nan,\n",
    "     'mean_veg': np.nan,'med_veg': np.nan,'percent_no_veg': np.nan,\n",
    "     'percent_bare_soil': np.nan,'percent_any_veg': np.nan,\n",
    "     'percent_sparse_veg': np.nan,'percent_dense_veg': np.nan})\n",
    "df_apr = df_jan.copy()\n",
    "df_jul = df_jan.copy()\n",
    "df_oct = df_jan.copy()\n",
    "\n",
    "# Create dataframe of months\n",
    "months_dataframes = {'January': df_jan, 'April': df_apr, 'July': df_jul, 'October': df_oct}\n",
    "\n",
    "# Collect data for each year\n",
    "df_all = []\n",
    "\n",
    "# Loop through years\n",
    "for year in range(2023,2023 + 1):\n",
    "\n",
    "    # Loop through catchment polygons\n",
    "    for i in range(0,len(gdf_sites)):\n",
    "        print(\"Processing MODIS for:\", str(year), gdf_sites.iloc[i]['site_id'],\n",
    "          f\"({i + 1}/{len(gdf_sites)})\")\n",
    "\n",
    "        # Load the catchment polygon\n",
    "        catchment_polygon = gdf_sites.geometry.iloc[i]\n",
    "\n",
    "        # Select catchment bounding box\n",
    "        bbox = site_bboxes[i]\n",
    "\n",
    "        # Select dates\n",
    "        months = {\n",
    "            \"January\": \"01\",\n",
    "            \"April\": \"04\",\n",
    "            \"July\": \"07\",\n",
    "            \"October\": \"10\",\n",
    "        }\n",
    "        items_season = dict()\n",
    "\n",
    "        # Search using bounding box coordinates\n",
    "        items_full = []\n",
    "        for name, number in months.items():\n",
    "            datetime = f\"{year}-{number}\"\n",
    "            search = catalog.search(\n",
    "                collections=[\"modis-13A1-061\"],\n",
    "                bbox=bbox,\n",
    "                datetime=datetime,\n",
    "            )\n",
    "            items_season[name] = search.item_collection()[0]\n",
    "            items = list(search.item_collection())\n",
    "            items_trunc = items[0:len(set([tuple(x.bbox) for x in items]))]\n",
    "            items_full += items_trunc\n",
    "\n",
    "        # Load and merge data into xarray\n",
    "        datasets = []\n",
    "        item_num = 0\n",
    "        for item in items_full:\n",
    "            item_num += 1\n",
    "            print(\"Processing item:\", f\"{item_num}/{len(items_full)}\")\n",
    "            data = odc.stac.load(\n",
    "                [item],\n",
    "                crs=\"EPSG:32610\",\n",
    "                bands=\"500m_16_days_NDVI\",\n",
    "                resolution=500,\n",
    "                bbox=bbox)\n",
    "            try:\n",
    "                # Clip data for each catchment polygon\n",
    "                data_clipped = data.rio.clip(\n",
    "                    gdf_sites.geometry.apply(mapping)[[i]], gdf_sites.crs)\n",
    "                # Mask areas outside the catchment polygon with NaN\n",
    "                mask = ~data_clipped.isnull()\n",
    "                data_clipped = data_clipped.where(mask)\n",
    "                # Append data\n",
    "                datasets.append(data_clipped)\n",
    "            except rioxarray.exceptions.NoDataInBounds:\n",
    "                continue  # Skip to the next item if no data is found\n",
    "\n",
    "        # Merge the datasets using xarray\n",
    "        merged_data = xr.concat(datasets, dim='item_index').mean(dim='item_index')\n",
    "\n",
    "        # Convert data to raster\n",
    "        raster = items_season[\"January\"].assets[\"500m_16_days_NDVI\"].extra_fields[\"raster:bands\"]\n",
    "        data = merged_data[\"500m_16_days_NDVI\"] * raster[0][\"scale\"]\n",
    "\n",
    "        # Clip data again so outside values are NaN\n",
    "        data_clipped = data.rio.clip(gdf_sites.geometry.apply(mapping)[[i]], gdf_sites.crs)\n",
    "\n",
    "        # Iterate through each month DataFrame\n",
    "        for month, df in months_dataframes.items():\n",
    "\n",
    "            # Label year\n",
    "            df.at[i,'year'] = year\n",
    "\n",
    "            # Select season\n",
    "            data_season = data_clipped.sel(time=data['time.month'] == int(months[month]))[0]\n",
    "\n",
    "             # Label month\n",
    "            df.at[i,'month'] = np.datetime_as_string(data_season.time.values, unit='M')[-2:]\n",
    "\n",
    "            # Extract mean, minimum, and average vegetation for catchment\n",
    "            df.at[i,'max_veg'] = np.nanmean(data_season)\n",
    "            df.at[i,'min_veg'] = np.nanmin(data_season)\n",
    "            df.at[i,'mean_veg'] = np.nanmean(data_season)\n",
    "            df.at[i,'med_veg'] = np.nanmedian(data_season)\n",
    "\n",
    "            # Calculate percent vegetation exceeding various thresholds\n",
    "            total_cells = np.sum(~np.isnan(data_season.values))\n",
    "            df.at[i,'percent_no_veg'] = np.sum(data_season.values < 0) / total_cells\n",
    "            df.at[i,'percent_bare_soil'] = np.sum(\n",
    "                (data_season.values < 0.01) & (data_season.values > -0.01)) / total_cells\n",
    "            df.at[i,'percent_any_veg'] = np.sum(data_season.values > 0) / total_cells\n",
    "            df.at[i,'percent_sparse_veg'] = np.sum(\n",
    "                (data_season.values > 0.1) & (data_season.values < 0.5)) / total_cells\n",
    "            df.at[i,'percent_dense_veg'] = np.sum(data_season.values > 0.6) / total_cells\n",
    "\n",
    "             # Export clipped and compressed raster file\n",
    "            data_season.rio.to_raster('assets/data/modis/' + gdf_sites.iloc[i].site_id\n",
    "                                      + '_' + str(year) + '_' + month + '_nvdi.tif')\n",
    "\n",
    "    # Combine month dataframes\n",
    "    df_year = pd.concat([df_jan, df_apr, df_jul, df_oct], ignore_index=True)\n",
    "    df_all.append(df_year)\n",
    "    print('\\n###################################################\\n')\n",
    "\n",
    "# Export dataframe\n",
    "df = pd.concat(df_all, ignore_index=True)\n",
    "df.to_csv('assets/data/modis/modis_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2599af23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
