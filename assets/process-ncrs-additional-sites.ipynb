{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292a2946",
   "metadata": {},
   "source": [
    "# Process NRCS Additional Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09087f",
   "metadata": {},
   "source": [
    "### Prepare Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56f37b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:29:19.547214Z",
     "start_time": "2023-12-20T21:29:19.540234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import system libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import data manipulation librariaes\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import geospatial libraries\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "\n",
    "# Import API libraries\n",
    "import requests\n",
    "\n",
    "# Import progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set working directory\n",
    "#os.chdir('/Users/jessicarapson/Documents/GitHub/water-supply-forecast')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178d6f8",
   "metadata": {},
   "source": [
    "### Load Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e9c4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:29:21.085378Z",
     "start_time": "2023-12-20T21:29:20.851060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load original sites\n",
    "mflow_orig = pd.read_csv(os.path.join(path, 'data/train_monthly_naturalized_flow.csv'))\n",
    "metad_orig = pd.read_csv(os.path.join(path, 'data/metadata.csv'))\n",
    "\n",
    "# Load additional sites\n",
    "mflow_ncrs = pd.read_csv(os.path.join('data/supplementary_nrcs_train_monthly_naturalized_flow.csv'))\n",
    "metad_ncrs = pd.read_csv(os.path.join('data/supplementary_nrcs_metadata.csv'))\n",
    "\n",
    "# Transform data for combination\n",
    "mflow_ncrs = mflow_ncrs.rename(columns={'nrcs_id': 'site_id'})\n",
    "metad_ncrs = metad_ncrs.rename(columns={'nrcs_id': 'site_id'})\n",
    "metad_ncrs['season_start_month'] = 4\n",
    "metad_ncrs['season_end_month'] = 7\n",
    "metad_orig = metad_orig[metad_ncrs.columns]\n",
    "\n",
    "# Combine dataframes\n",
    "all_mflow = pd.concat([mflow_orig, mflow_ncrs], ignore_index=True)\n",
    "all_metad = pd.concat([metad_orig, metad_ncrs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a3b59",
   "metadata": {},
   "source": [
    "### Add HydroBASIN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bd73db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:29:34.652546Z",
     "start_time": "2023-12-20T21:29:30.895403Z"
    }
   },
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/Users/emilryd/programming/water-supply-forecast/assets/data/additional_sites/hydroBASINS_additional.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCPLE_OpenFailedError\u001B[0m                      Traceback (most recent call last)",
      "File \u001B[0;32mfiona/ogrext.pyx:136\u001B[0m, in \u001B[0;36mfiona.ogrext.gdal_open_vector\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mfiona/_err.pyx:291\u001B[0m, in \u001B[0;36mfiona._err.exc_wrap_pointer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mCPLE_OpenFailedError\u001B[0m: /Users/emilryd/programming/water-supply-forecast/assets/data/additional_sites/hydroBASINS_additional.gpkg: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mDriverError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load in attribute geospatial data (this takes a while)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m gdf_basins \u001B[38;5;241m=\u001B[39m \u001B[43mgpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/additional_sites/hydroBASINS_additional.gpkg\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Convert coordinates to geometry\u001B[39;00m\n\u001B[1;32m      5\u001B[0m geometry \u001B[38;5;241m=\u001B[39m [Point(xy) \u001B[38;5;28;01mfor\u001B[39;00m xy \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(all_metad[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m'\u001B[39m], all_metad[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m'\u001B[39m])]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/geopandas/io/file.py:297\u001B[0m, in \u001B[0;36m_read_file\u001B[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001B[0m\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m         path_or_bytes \u001B[38;5;241m=\u001B[39m filename\n\u001B[0;32m--> 297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_file_fiona\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_bytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_bytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown engine \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mengine\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/geopandas/io/file.py:338\u001B[0m, in \u001B[0;36m_read_file_fiona\u001B[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001B[0m\n\u001B[1;32m    335\u001B[0m     reader \u001B[38;5;241m=\u001B[39m fiona\u001B[38;5;241m.\u001B[39mopen\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m fiona_env():\n\u001B[0;32m--> 338\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mreader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_bytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m features:\n\u001B[1;32m    339\u001B[0m         crs \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mcrs_wkt\n\u001B[1;32m    340\u001B[0m         \u001B[38;5;66;03m# attempt to get EPSG code\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/fiona/env.py:457\u001B[0m, in \u001B[0;36mensure_env_with_credentials.<locals>.wrapper\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    454\u001B[0m     session \u001B[38;5;241m=\u001B[39m DummySession()\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m env_ctor(session\u001B[38;5;241m=\u001B[39msession):\n\u001B[0;32m--> 457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/fiona/__init__.py:292\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001B[0m\n\u001B[1;32m    289\u001B[0m     path \u001B[38;5;241m=\u001B[39m parse_path(fp)\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 292\u001B[0m     colxn \u001B[38;5;241m=\u001B[39m \u001B[43mCollection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdriver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m        \u001B[49m\u001B[43menabled_drivers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menabled_drivers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unsupported_drivers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_unsupported_drivers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    303\u001B[0m     colxn \u001B[38;5;241m=\u001B[39m Collection(\n\u001B[1;32m    304\u001B[0m         path,\n\u001B[1;32m    305\u001B[0m         mode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    315\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/fiona/collection.py:243\u001B[0m, in \u001B[0;36mCollection.__init__\u001B[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001B[0m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession \u001B[38;5;241m=\u001B[39m Session()\n\u001B[0;32m--> 243\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession \u001B[38;5;241m=\u001B[39m WritingSession()\n",
      "File \u001B[0;32mfiona/ogrext.pyx:588\u001B[0m, in \u001B[0;36mfiona.ogrext.Session.start\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mfiona/ogrext.pyx:143\u001B[0m, in \u001B[0;36mfiona.ogrext.gdal_open_vector\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mDriverError\u001B[0m: /Users/emilryd/programming/water-supply-forecast/assets/data/additional_sites/hydroBASINS_additional.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Load in attribute geospatial data (this takes a while)\n",
    "gdf_basins = gpd.read_file(os.path.join(path, 'data/additional_sites/hydroBASINS_additional.gpkg'))\n",
    "\n",
    "# Convert coordinates to geometry\n",
    "geometry = [Point(xy) for xy in zip(all_metad['longitude'], all_metad['latitude'])]\n",
    "gdf_sites = gpd.GeoDataFrame(all_metad, geometry=geometry, crs=gdf_basins.crs)\n",
    "\n",
    "# Select columns of interest\n",
    "cols_int = ['inu_pc_smn','inu_pc_smx','inu_pc_slt','inu_pc_umn','inu_pc_umx',\n",
    "            'inu_pc_ult','lka_pc_sse','lka_pc_use','dor_pc_pva','slp_dg_sav',\n",
    "            'slp_dg_uav','sgr_dk_sav','tmp_dc_uyr','ari_ix_sav','ari_ix_uav',\n",
    "            'cmi_ix_uyr','snw_pc_uyr','glc_pc_s01','glc_pc_s02','glc_pc_s03',\n",
    "            'glc_pc_s04','glc_pc_s05','glc_pc_s06','glc_pc_s07','glc_pc_s08',\n",
    "            'glc_pc_s09','glc_pc_s10','glc_pc_s11','glc_pc_s12','glc_pc_s13',\n",
    "            'glc_pc_s14','glc_pc_s15','glc_pc_s16','glc_pc_s17','glc_pc_s18',\n",
    "            'glc_pc_s19','glc_pc_s20','glc_pc_s21','glc_pc_s22','glc_pc_u01',\n",
    "            'glc_pc_u02','glc_pc_u03','glc_pc_u04','glc_pc_u05','glc_pc_u06',\n",
    "            'glc_pc_u07','glc_pc_u08','glc_pc_u09','glc_pc_u10','glc_pc_u11',\n",
    "            'glc_pc_u12','glc_pc_u13','glc_pc_u14','glc_pc_u15','glc_pc_u16',\n",
    "            'glc_pc_u17','glc_pc_u18','glc_pc_u19','glc_pc_u20','glc_pc_u21',\n",
    "            'glc_pc_u22','wet_pc_sg1','wet_pc_sg2','wet_pc_ug1','wet_pc_ug2',\n",
    "            'for_pc_sse','for_pc_use','crp_pc_sse','crp_pc_use','pst_pc_sse',\n",
    "            'pst_pc_use','ire_pc_sse','ire_pc_use','gla_pc_sse','gla_pc_use',\n",
    "            'prm_pc_sse','prm_pc_use','pac_pc_sse','pac_pc_use','cly_pc_sav',\n",
    "            'cly_pc_uav','slt_pc_sav','slt_pc_uav','snd_pc_sav','snd_pc_uav',\n",
    "            'soc_th_sav','soc_th_uav','swc_pc_syr','swc_pc_uyr','swc_pc_s01',\n",
    "            'swc_pc_s02','swc_pc_s03','swc_pc_s04','swc_pc_s05','swc_pc_s06',\n",
    "            'swc_pc_s07','swc_pc_s08','swc_pc_s09','swc_pc_s10','swc_pc_s11',\n",
    "            'swc_pc_s12','kar_pc_sse','kar_pc_use','ero_kh_sav','ero_kh_uav',\n",
    "            'ppd_pk_sav','ppd_pk_uav','urb_pc_sse','urb_pc_use','nli_ix_sav',\n",
    "            'nli_ix_uav','rdd_mk_sav','rdd_mk_uav','hft_ix_s93','hft_ix_u93',\n",
    "            'hft_ix_s09','hft_ix_u09','gwt_cm_sav','run_mm_syr','lkv_mc_usu',\n",
    "            'rev_mc_usu','ria_ha_ssu','ria_ha_usu','riv_tc_ssu','riv_tc_usu',\n",
    "            'pre_mm_uyr','pet_mm_syr','pet_mm_s01', 'pet_mm_s02','pet_mm_s03',\n",
    "            'pet_mm_s04','pet_mm_s05','pet_mm_s06','pet_mm_s07','pet_mm_s08',\n",
    "            'pet_mm_s09','pet_mm_s10','pet_mm_s11','pet_mm_s12','pet_mm_uyr',\n",
    "            'aet_mm_syr','aet_mm_s01','aet_mm_s02','aet_mm_s03','aet_mm_s04',\n",
    "            'aet_mm_s05','aet_mm_s06','aet_mm_s07','aet_mm_s08','aet_mm_s09',\n",
    "            'aet_mm_s10','aet_mm_s11','aet_mm_s12','aet_mm_uyr','pop_ct_ssu',\n",
    "            'pop_ct_usu','clz_cl_smj','cls_cl_smj','glc_cl_smj','pnv_cl_smj',\n",
    "            'wet_cl_smj','tbi_cl_smj','tec_cl_smj','fmh_cl_smj','fec_cl_smj',\n",
    "            'lit_cl_smj', 'SUB_AREA', 'UP_AREA','COAST','ORDER_','ENDO','geometry']\n",
    "\n",
    "# Join relevant basin data\n",
    "gdf_join = gpd.sjoin(gdf_sites, gdf_basins[cols_int], how='left', op='within')\n",
    "\n",
    "# Code missing values as NaN\n",
    "gdf_join = gdf_join.replace(-9999, np.nan)\n",
    "\n",
    "# Replace points with basin polygon\n",
    "polygons = gdf_join.merge(gdf_basins, how='left', left_on='index_right', right_index=True)\n",
    "gdf_join.geometry = polygons.geometry_y\n",
    "\n",
    "# Drop extra columns\n",
    "cols_drop = ['nrcs_name', 'usgs_id', 'elevation', 'latitude', 'longitude',\n",
    "             'season_start_month', 'season_end_month', 'geometry', 'index_right']\n",
    "gdf_join = gdf_join.drop(cols_drop, axis=1)\n",
    "\n",
    "# Convert categorical columns to strings\n",
    "cols_cat = ['COAST', 'ORDER_', 'ENDO', 'clz_cl_smj', 'cls_cl_smj',\n",
    "            'glc_cl_smj', 'pnv_cl_smj', 'wet_cl_smj', 'tbi_cl_smj',\n",
    "            'tec_cl_smj', 'fmh_cl_smj', 'fec_cl_smj', 'lit_cl_smj']\n",
    "gdf_join[cols_cat] = gdf_join[cols_cat].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e3ae5",
   "metadata": {},
   "source": [
    "### Add SWANN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a276146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:30:36.405161Z",
     "start_time": "2023-12-20T21:30:13.154707Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:23<05:01,  7.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m     target \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(LOCATION, fn)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(target, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 17\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m         f\u001B[38;5;241m.\u001B[39mwrite(response\u001B[38;5;241m.\u001B[39mcontent)\n\u001B[1;32m     20\u001B[0m swe_volumes \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/sessions.py:747\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    744\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 747\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_content(CONTENT_CHUNK_SIZE)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/urllib3/response.py:934\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    933\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 934\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    937\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/urllib3/response.py:877\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    874\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[1;32m    875\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[0;32m--> 877\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    879\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/urllib3/response.py:812\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    809\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 812\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    822\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/site-packages/urllib3/response.py:797\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    794\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 797\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/http/client.py:465\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    464\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 465\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/ssl.py:1278\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1275\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1276\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1277\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1278\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1279\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/water_supply_forecast/lib/python3.11/ssl.py:1134\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Select years\n",
    "START_YEAR = 1981\n",
    "END_YEAR = 2023\n",
    "YEARS = [y for y in range(START_YEAR, END_YEAR)]\n",
    "\n",
    "# Select data\n",
    "ROOT = 'https://climate.arizona.edu/data/UA_SWE/'\n",
    "LOCATION = 'data/swann'\n",
    "\n",
    "# Download data\n",
    "os.makedirs(LOCATION, exist_ok=True)\n",
    "for yr in tqdm(YEARS):\n",
    "    fn = f'UA_SWE_Depth_WY{yr}.nc'\n",
    "    url = ROOT + '/' + fn\n",
    "    target = os.path.join(LOCATION, fn)\n",
    "    with open(target, 'wb') as f:\n",
    "        response = requests.get(url, verify=False)\n",
    "        f.write(response.content)\n",
    "\n",
    "swe_volumes = []\n",
    "for yr in tqdm(YEARS):\n",
    "    fn = os.path.join('data/swann', f'UA_SWE_Depth_WY{yr}.nc')\n",
    "    try:\n",
    "        ds = rioxarray.open_rasterio(fn, variable='SWE', mask_and_scale=True)\n",
    "    except IOError:\n",
    "        continue\n",
    "\n",
    "    # Perform an initial clip to reduce the size of the array\n",
    "    ds = ds.rio.write_crs(4326)\n",
    "    ds = ds.rio.reproject(\"EPSG:4326\")\n",
    "\n",
    "    ds['SWE'] /= 1000  # mm -> m\n",
    "    ds = ds.fillna(0)\n",
    "    ds = ds.rio.write_crs(4326)\n",
    "    ds_clipped_rgn = ds.rio.clip(gdf_join.geometry.values)\n",
    "\n",
    "    for i in range(0, len(gdf_join)):\n",
    "        try:\n",
    "            # Clip to current polygon\n",
    "            ds_clipped_poly = ds_clipped_rgn.rio.clip([gdf_join.iloc[i].geometry])\n",
    "\n",
    "            # Set -999 to nan then convert to dataframe\n",
    "            df = ds_clipped_poly.to_dataframe()\n",
    "            df = df.dropna()\n",
    "            df = df.reset_index()\n",
    "\n",
    "            # Group by time and average over grid cells\n",
    "            swe_vol = df.groupby(['time'])['SWE'].mean()\n",
    "\n",
    "            # Format dataframe\n",
    "            swe_vol = pd.DataFrame(swe_vol).reset_index()\n",
    "            swe_vol['site_id'] = gdf_join.iloc[i].site_id\n",
    "            swe_vol = swe_vol.set_index(['site_id', 'time'])\n",
    "            swe_vol = swe_vol.rename({'SWE': 'SWE_depth_m'}, axis=1)\n",
    "            swe_volumes.append(swe_vol)\n",
    "        except Exception as e:\n",
    "            print(f\"No data found for: {gdf_join.iloc[i]['site_id']}\")\n",
    "            continue\n",
    "\n",
    "# Concatenate dataframes and write output\n",
    "swe_volumes = pd.concat(swe_volumes, axis=0)\n",
    "swe_volumes.to_csv(\"assets/data/additional_sites/swann_swe.csv\")\n",
    "\n",
    "# Filter to years of interest\n",
    "swe_volumes_week = swe_volumes.copy()\n",
    "swe_volumes_week['date'] = pd.to_datetime(swe_volumes['time']).dt.date\n",
    "swe_volumes_week = swe_volumes_week[pd.to_datetime(\n",
    "    swe_volumes_week['date']) >= pd.Timestamp(\"1985-01-01\")]\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = datetime.date(1985, 1, 1)\n",
    "end_date = datetime.date(2024, 1, 1)\n",
    "\n",
    "# Initialize an empty list to store weeks\n",
    "week_list = []\n",
    "\n",
    "# Generate weeks between start_date and end_date\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    for day in [1, 8, 15, 22]:\n",
    "        week = current_date + datetime.timedelta(days=(day - current_date.weekday() - 1))\n",
    "        if week < end_date:\n",
    "            week_list.append(week.strftime('%Y-%m-%d'))\n",
    "    current_date += datetime.timedelta(days=7)\n",
    "    \n",
    "# Function to round down the day to the nearest value less than or equal to the day\n",
    "def round_day_down(date):\n",
    "    day = date.day\n",
    "    nearest_values = [1, 8, 15, 22]\n",
    "\n",
    "    # Find the nearest value less than or equal to the day\n",
    "    rounded_day = max(filter(lambda x: x <= day, nearest_values))\n",
    "    return date.replace(day=rounded_day)\n",
    "\n",
    " # Create a new column 'Rounded_Day_Column' based on 'Date_Column'\n",
    "swe_volumes_week['week_start_date'] = swe_volumes_week['date'].apply(round_day_down)\n",
    "swe_volumes_week = swe_volumes_week.drop(['date', 'time'], axis=1)\n",
    "\n",
    "# Aggregate by week\n",
    "swe_volumes_week = swe_volumes_week.groupby(\n",
    "    ['site_id','week_start_date']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627d551",
   "metadata": {},
   "source": [
    "### Add USGS Streamflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664947ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-20T21:30:03.398140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing nrcs_name\n",
    "all_metad['nrcs_name'] = np.where(\n",
    "    all_metad['nrcs_name'].isna(), all_metad['site_id'], all_metad['nrcs_name'])\n",
    "\n",
    "# Create empty list\n",
    "usbr_all = []\n",
    "\n",
    "# Loop through years\n",
    "for year in range(1985, 2025):\n",
    "    print(f\"#######Retreiving data for {year}#######\")\n",
    "\n",
    "    # Loop through forecasting sites\n",
    "    site_list = [item.lower().replace(' ', '_') for item in all_metad['nrcs_name']]\n",
    "    for site in site_list:\n",
    "        file_path = f\"./assets/data/additional_sites/support_data/usgs_streamflow/FY{year}/{site}.csv\"\n",
    "\n",
    "        #  # Check if the file exists for the station\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found for site {site}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Read in daily flow data for the selected year\n",
    "        flow_data = pd.read_csv(file_path)\n",
    "        flow_data['site_id'] = site\n",
    "\n",
    "        # Select data of interest\n",
    "        flow_data = flow_data[['site_id', 'datetime', '00060_Mean']]\n",
    "\n",
    "        # Append to list\n",
    "        usbr_all.append(flow_data)\n",
    "\n",
    "# Combine data\n",
    "result = pd.concat(usbr_all, axis=0, ignore_index=True)\n",
    "\n",
    "# Perform additional cleaning\n",
    "result['datetime'] = pd.to_datetime(result['datetime']).dt.strftime('%Y-%m-%d')\n",
    "result['00060_Mean'] = np.where(result['00060_Mean'] == -999999, np.nan, result['00060_Mean'])\n",
    "\n",
    "# Filter to years of interest\n",
    "result_week = result.copy()\n",
    "result_week['date'] = pd.to_datetime(result['datetime']).dt.date\n",
    "result_week = result_week[pd.to_datetime(\n",
    "    result_week['date']) >= pd.Timestamp(\"1984-01-01\")]\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = datetime.date(1984, 1, 1)\n",
    "end_date = datetime.date(2024, 1, 1)\n",
    "\n",
    "# Initialize an empty list to store weeks\n",
    "week_list = []\n",
    "\n",
    "# Generate weeks between start_date and end_date\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    for day in [1, 8, 15, 22]:\n",
    "        week = current_date + datetime.timedelta(days=(day - current_date.weekday() - 1))\n",
    "        if week < end_date:\n",
    "            week_list.append(week.strftime('%Y-%m-%d'))\n",
    "    current_date += datetime.timedelta(days=7)\n",
    "    \n",
    "# Function to round down the day to the nearest value less than or equal to the day\n",
    "def round_day_down(date):\n",
    "    day = date.day\n",
    "    nearest_values = [1, 8, 15, 22]\n",
    "\n",
    "    # Find the nearest value less than or equal to the day\n",
    "    rounded_day = max(filter(lambda x: x <= day, nearest_values))\n",
    "    return date.replace(day=rounded_day)\n",
    "\n",
    " # Create a new column 'Rounded_Day_Column' based on 'Date_Column'\n",
    "result_week['week_start_date'] = result_week['date'].apply(round_day_down)\n",
    "result_week = result_week.drop(['date', 'datetime'], axis=1)\n",
    "\n",
    "# Aggregate by week\n",
    "result_week = result_week.groupby(\n",
    "    ['site_id','week_start_date']).mean().reset_index()\n",
    "\n",
    "# Export data\n",
    "result_week.to_csv('./assets/data/additional_sites/usgs_streamflow.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de7e53",
   "metadata": {},
   "source": [
    "### Combine Data and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d60e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:30:58.132364Z",
     "start_time": "2023-12-20T21:30:58.129605Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'swe_volumes_week' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Link area to snow volume data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m swe_volumes_area \u001B[38;5;241m=\u001B[39m \u001B[43mswe_volumes_week\u001B[49m\u001B[38;5;241m.\u001B[39mmerge(\n\u001B[1;32m      3\u001B[0m     gdf_join[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msite_id\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUB_AREA\u001B[39m\u001B[38;5;124m'\u001B[39m]], how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msite_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Scale snow volume by area\u001B[39;00m\n\u001B[1;32m      6\u001B[0m swe_volumes_area[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSWE_depth_m_AREA_SCALED\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m swe_volumes_area[\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSWE_depth_m\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m swe_volumes_area[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUB_AREA\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'swe_volumes_week' is not defined"
     ]
    }
   ],
   "source": [
    "# Link area to snow volume data\n",
    "swe_volumes_area = swe_volumes_week.merge(\n",
    "    gdf_join[['site_id','SUB_AREA']], how='left', on='site_id')\n",
    "\n",
    "# Scale snow volume by area\n",
    "swe_volumes_area['SWE_depth_m_AREA_SCALED'] = swe_volumes_area[\n",
    "    'SWE_depth_m'] * swe_volumes_area['SUB_AREA']\n",
    "\n",
    "# Drop area column\n",
    "swe_volumes_area = swe_volumes_area.drop('SUB_AREA', axis=1)\n",
    "\n",
    "# Export data\n",
    "all_metad.to_csv(\"assets/data/additional_sites/metadata.csv\", index=False)\n",
    "swe_volumes_area.to_csv(\"assets/data/additional_sites/swann_swe.csv\", index=False)\n",
    "all_mflow.to_csv(\"assets/data/additional_sites/train_monthly_naturalized_flow.csv\", index=False)\n",
    "gdf_join.to_csv(\"assets/data/additional_sites/hydrobasins_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff38490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into delta models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384ac31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
