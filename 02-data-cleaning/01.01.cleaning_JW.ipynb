{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in libraries\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Set the directory path where your files are located\n",
    "folder_path = \"C:\\\\Users\\\\johnh\\\\OneDrive\\\\Documents\\\\GitHub\\\\water-supply-forecast\\\\assets\\\\data\\\\teleconnections\"\n",
    "folder_path_flow = \"C:\\\\Users\\\\johnh\\\\OneDrive\\\\Documents\\\\GitHub\\\\water-supply-forecast\\\\assets\\\\data\"\n",
    "folder_path_grace = \"C:\\\\Users\\\\johnh\\\\OneDrive\\\\Documents\\\\GitHub\\\\water-supply-forecast\\\\assets\\\\data\\\\grace_indicators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map month abbreviations to numeric values\n",
    "month_to_num = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4,\n",
    "    'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8,\n",
    "    'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "# Dictionary to map month abbreviations to numeric values\n",
    "month_to_num_up = {\n",
    "    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4,\n",
    "    'MAY': 5, 'JUN': 6, 'JUL': 7, 'AUG': 8,\n",
    "    'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for mjo dataset\n",
    "df_mjo = pd.read_table(os.path.join(folder_path,\"mjo.txt\"),delim_whitespace=True, skiprows=1)\n",
    "df_mjo = df_mjo.iloc[1:]\n",
    "df_mjo.columns = df_mjo.columns.str.strip()\n",
    "df_mjo = df_mjo.add_prefix('mjo')\n",
    "df_mjo = df_mjo[df_mjo['mjo20E'] != '*****'] # Remove future values (missing)\n",
    "\n",
    "df_mjo['year'] = df_mjo['mjoPENTAD'].astype(str).str[:4].astype(int)\n",
    "df_mjo['month'] = df_mjo['mjoPENTAD'].astype(str).str[4:6].astype(int)\n",
    "df_mjo['day'] = df_mjo['mjoPENTAD'].astype(str).str[6:8].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for nino dataset\n",
    "df_nino = pd.read_table(os.path.join(folder_path,\"nino_regions_sst.txt\"),delim_whitespace=True)\n",
    "df_nino = df_nino.rename(columns={'YR':'year', 'MON':'month'})\n",
    "df_nino = df_nino.rename(columns={c: 'nino'+c for c in df_nino.columns if c not in ['year', 'month']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for oni dataset\n",
    "df_oni = pd.read_table(os.path.join(folder_path,\"oni.txt\"),delim_whitespace=True)\n",
    "df_oni = df_oni.rename(columns={'YR':'year'})\n",
    "df_oni['month'] = 1 #Assume month of collection is january\n",
    "df_oni = df_oni.rename(columns={c: 'oni'+c for c in df_oni.columns if c not in ['year', 'month']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for pdo dataset\n",
    "df_pdo = pd.read_table(os.path.join(folder_path,\"pdo.txt\"),delim_whitespace=True,skiprows=1)\n",
    "df_pdo = pd.melt(df_pdo, id_vars=['Year'], var_name='Month', value_name='pdo')\n",
    "df_pdo = df_pdo.rename(columns={'Year':'year', 'Month':'month'})\n",
    "df_pdo = df_pdo[df_pdo['pdo'] != 99.99] # Remove future values (missing)\n",
    "df_pdo['month'] = df_pdo['month'].map(month_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for pna dataset\n",
    "df_pna = pd.read_table(os.path.join(folder_path,\"pna.txt\"),delim_whitespace=True)\n",
    "df_pna = pd.melt(df_pna, id_vars=['year'], var_name='month', value_name='pna')\n",
    "df_pna['month'] = df_pna['month'].map(month_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for soi dataset\n",
    "df_soi1 = pd.read_table(os.path.join(folder_path,\"soi1.txt\"),delim_whitespace=True,skiprows=3)\n",
    "df_soi1.columns = df_soi1.columns.str.strip()\n",
    "df_soi1 = pd.melt(df_soi1, id_vars=['YEAR'], var_name='month', value_name='soi_anom')\n",
    "df_soi1 = df_soi1.rename(columns={'YEAR':'year'})\n",
    "df_soi1['month'] = df_soi1['month'].map(month_to_num_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for soi dataset\n",
    "df_soi2 = pd.read_table(os.path.join(folder_path,\"soi2.txt\"),delim_whitespace=True,skiprows=3)\n",
    "df_soi2.columns = df_soi2.columns.str.strip()\n",
    "df_soi2 = pd.melt(df_soi2, id_vars=['YEAR'], var_name='month', value_name='soi_sd')\n",
    "df_soi2 = df_soi2.rename(columns={'YEAR':'year'})\n",
    "df_soi2['month'] = df_soi2['month'].map(month_to_num_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge code\n",
    "data_frames = [df_mjo, df_nino, df_oni, df_pdo, df_pna, df_soi1, df_soi2]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['year', 'month'],\n",
    "                                            how='outer'), data_frames)\n",
    "\n",
    "# Re-order columns\n",
    "column_order = ['year'] + ['month'] + [col for col in df_merged.columns if col != ['month','year']]\n",
    "df_merged = df_merged[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in streamflows\n",
    "df_flow = pd.read_csv(os.path.join(folder_path_flow,\"train_monthly_naturalized_flow.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2476\\144954498.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Merge code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_mjo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_nino\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_oni\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pdo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_soi1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_soi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_flow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['year', 'month', 'day'],\n\u001b[0m\u001b[0;32m      4\u001b[0m                                             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2476\\144954498.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right)\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['year', 'month', 'day'],\n\u001b[0m\u001b[0;32m      4\u001b[0m                                             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'day'"
     ]
    }
   ],
   "source": [
    "# Merge code\n",
    "data_frames = [df_mjo, df_nino, df_oni, df_pdo, df_pna, df_soi1, df_soi2, df_flow]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['year', 'month'],\n",
    "                                            how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for grace indicators\n",
    "df_grace = pd.read_csv(os.path.join(folder_path_grace,\"grace_aggregated.csv\"))\n",
    "\n",
    "# Convert 'time' to datetime format\n",
    "df_grace['time'] = pd.to_datetime(df_grace['time'])\n",
    "\n",
    "# Extract day, month, and year into separate columns\n",
    "df_grace['day'] = df_grace['time'].dt.day\n",
    "df_grace['month'] = df_grace['time'].dt.month\n",
    "df_grace['year'] = df_grace['time'].dt.year\n",
    "\n",
    "df_grace.drop('time', axis=1, inplace=True)\n",
    "\n",
    "data_frames = [df_merged, ]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['year', 'month'],\n",
    "                                            how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the DataFrame to a CSV file\n",
    "df_merged.to_csv('merged_dataframe.csv', index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is adjusts variable types, then standardises numeric variables and one-hot encodes categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display variable names and data types\n",
    "variable_types_df = pd.DataFrame({'Variable': df_merged.columns, 'Data Type': df_merged.dtypes.values})\n",
    "\n",
    "# Iterate over columns\n",
    "for column_name in df_merged.columns:\n",
    "    # Check if the column name contains the substring 'mjo'\n",
    "    if 'mjo' in column_name:\n",
    "        # Convert values to float using pd.to_numeric\n",
    "        df_merged[column_name] = pd.to_numeric(df_merged[column_name], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "def preprocess_column(df, column_name):\n",
    "    # Skip preprocessing for specified columns\n",
    "    if column_name in [\"month\", \"year\", \"day\"]:\n",
    "        return df\n",
    "    \n",
    "    # Check the data type of the column\n",
    "    column_dtype = df[column_name].dtype\n",
    "    \n",
    "    if column_dtype == 'object':\n",
    "        # If it's a categorical variable, perform one-hot encoding\n",
    "        df = pd.get_dummies(df, columns=[column_name], prefix=[column_name])\n",
    "    elif column_dtype in ['int64', 'float64']:\n",
    "        # If it's a numeric variable, standardize it\n",
    "        scaler = StandardScaler()\n",
    "        df[column_name] = scaler.fit_transform(df[[column_name]])\n",
    "    elif column_dtype == 'bool':\n",
    "        # If it's a binary variable, check if it's 0-1 coded and encode if not\n",
    "        unique_values = df[column_name].unique()\n",
    "        if set(unique_values) == {0, 1}:\n",
    "            print(f\"{column_name} is already 0-1 coded.\")\n",
    "        else:\n",
    "            label_encoder = LabelEncoder()\n",
    "            df[column_name] = label_encoder.fit_transform(df[column_name])\n",
    "    else:\n",
    "        print(f\"Warning: Unsupported data type for column {column_name}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    # Iterate over all columns in the DataFrame\n",
    "    for column_name in df.columns:\n",
    "        df = preprocess_column(df, column_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Perform preprocessing on all columns\n",
    "trans_vars = preprocess_dataframe(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the DataFrame to a CSV file\n",
    "trans_vars.to_csv('transformed_vars.csv', index=False)  # Set index=False to exclude the index column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
